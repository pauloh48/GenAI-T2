{
	"nodes":[
		{"id":"0f1c06ed1aa9df24","type":"text","text":"# U11. Redes Neurais","x":-562,"y":-81,"width":302,"height":61},
		{"id":"0508fc7b9734a8e2","type":"text","text":" **O que s√£o?**\n- Inspiradas no **c√©rebro humano**: neur√¥nios artificiais conectados entre si.\n- Transformam **entradas** (dados) em **sa√≠das** (respostas).\n- Aprendem **padr√µes complexos e n√£o lineares**.  \n    üëâ Usadas em classifica√ß√£o, regress√£o, vis√£o computacional, linguagem natural e at√© gera√ß√£o de imagens, m√∫sicas e textos.","x":-300,"y":-380,"width":637,"height":200},
		{"id":"12d3c74b249c8236","type":"text","text":"## Neur√¥nio Artificial","x":-130,"y":-45,"width":297,"height":51},
		{"id":"cd8c4fc8b24ca725","type":"text","text":"O **neur√¥nio biol√≥gico** recebe sinais, processa e manda a resposta para outros neur√¥nios.\n","x":253,"y":-80,"width":267,"height":120},
		{"id":"99cd4043facd89ba","type":"text","text":"Resumindo: o neur√¥nio artificial **pega informa√ß√µes, combina, ajusta e decide o que mandar para frente**.","x":253,"y":220,"width":427,"height":100},
		{"id":"3b56db8d58325d5e","type":"text","text":"O **neur√¥nio artificial** imita isso de forma simples:\n1. **Entradas (X)** ‚Üí s√£o os dados recebidos (ex.: altura, peso, cor do pixel).\n2. **Pesos (W)** ‚Üí cada entrada tem uma ‚Äúfor√ßa‚Äù diferente, como conex√µes mais fracas ou mais fortes.\n3. **Vi√©s (b)** ‚Üí um ajuste extra, como um ‚Äúempurr√£ozinho‚Äù na decis√£o.\n4. **Soma ponderada** ‚Üí entradas √ó pesos + vi√©s.\n5. **Fun√ß√£o de ativa√ß√£o (f)** ‚Üí decide se o neur√¥nio ‚Äúdispara‚Äù (ex.: 0 ou 1, ou valores entre 0 e 1).","x":600,"y":-300,"width":728,"height":240},
		{"id":"85969565cd5a2914","type":"text","text":"![[esquema_neuronio.png]]","x":800,"y":35,"width":421,"height":235},
		{"id":"f26411fdc298c78f","type":"text","text":"![[func_ativacao.png]]","x":1480,"y":-120,"width":583,"height":340,"color":"4"},
		{"id":"b0f49c4cff9aee22","type":"text","text":"## Multi-Layer Perceptron","x":-160,"y":460,"width":305,"height":60},
		{"id":"6345ac466a23dda8","type":"text","text":"**O que √©?**\n\n- √â uma **rede de v√°rios neur√¥nios artificiais organizados em camadas**.\n    \n- Foi poss√≠vel gra√ßas ao **backpropagation**, um algoritmo que ensina a rede a aprender com os erros.","x":253,"y":378,"width":584,"height":142},
		{"id":"3fb03f4067ee081f","type":"text","text":"![[multilayer_perceptron.png]]","x":253,"y":560,"width":584,"height":440},
		{"id":"47a227896098ccfd","type":"text","text":"**Estrutura b√°sica**\n\n1. **Camada de Entrada**\n    \n    - Recebe os dados brutos (ex.: pixels de uma imagem).\n        \n    - Cada dado √© multiplicado por um peso.\n        \n2. **Camadas Escondidas**\n    \n    - Fazem a ‚Äúm√°gica‚Äù: combinam informa√ß√µes e capturam padr√µes mais complexos.\n        \n    - Quanto mais camadas, maior a capacidade de aprender coisas dif√≠ceis.\n        \n3. **Camada de Sa√≠da**\n    \n    - D√° a resposta final (ex.: ‚Äúgato‚Äù ou ‚Äúcachorro‚Äù).\n        \n    - Pode trazer probabilidades de cada classe.","x":960,"y":616,"width":663,"height":328},
		{"id":"50efc7e79c51ccdf","type":"text","text":"* Treinamento\n![[feed_back.png]]","x":260,"y":1120,"width":577,"height":557},
		{"id":"4bf298160d55b783","type":"text","text":"- **Backpropagation** ‚Üí o erro √© enviado ‚Äúde volta‚Äù ajustando os pesos para que a rede melhore.","x":1006,"y":1560,"width":620,"height":60},
		{"id":"d15127852aafe292","type":"text","text":"- **Feedforward** ‚Üí dados entram, passam pelas camadas e chegam na sa√≠da.","x":1015,"y":1160,"width":611,"height":50},
		{"id":"026680ebf14a7a64","x":1440,"y":1639,"width":820,"height":161,"type":"text","text":"**erro** (diferen√ßa entre resposta correta e resposta do modelo) √© mensurado pela chamada **fun√ß√£o de custo**, tamb√©m chamada de fun√ß√£o de perda ou¬†_loss function_¬†em ingl√™s\n* **Fun√ß√£o de Custo** ‚Üí mede e reduz o erro a cada tentativa\n* **Gradient Descent** ‚Üí processo matem√°tico que vai ajustando os pesos passo a passo para **reduzir o erro**. Por isso _backpropagation_"},
		{"id":"b56f100048e0b276","x":1900,"y":1450,"width":620,"height":170,"type":"text","text":"**Problema cl√°ssico: _Vanishing Gradient_**\n- Quanto mais camadas, menor o ‚Äúsinal‚Äù do erro nas primeiras camadas.\n- Resultado: as camadas iniciais quase n√£o aprendem ‚Üí a rede fica ‚Äútravada‚Äù.  \n- Esse problema atrasou o avan√ßo das RNAs por anos, at√© aparecer o **Deep Learning** com novas fun√ß√µes de ativa√ß√£o (como a ReLU)"},
		{"id":"8e56c2650c5876ab","x":-520,"y":1960,"width":250,"height":60,"type":"text","text":"## Deep Learning"},
		{"id":"f656313c32173be0","x":-200,"y":1960,"width":250,"height":60,"type":"text","text":"#### Avan√ßos principais"},
		{"id":"d08a1039429fd729","x":320,"y":1703,"width":628,"height":180,"type":"text","text":"1. **Fun√ß√£o ReLU**\n\t- Antes usava-se a **sigm√≥ide**, que ‚Äúapagava‚Äù o gradiente em redes grandes (_vanishing gradient_).\n\t- A **ReLU** resolveu isso: deixa passar valores positivos e zera os negativos.  \n\nResultado: redes mais f√°ceis de treinar e com muitas camadas."},
		{"id":"a859daefde709b23","x":320,"y":1926,"width":617,"height":94,"type":"text","text":"2. **Otimizadores**\n\t- Novos algoritmos (ex.: Adam, RMSProp) aceleraram o ajuste dos pesos.  \n\t  Resultado: treinamento mais r√°pido e eficiente."},
		{"id":"8f6b6c923b423858","x":320,"y":2063,"width":617,"height":127,"type":"text","text":"3. **Inicializa√ß√£o dos Pesos**\n\t- Em vez de come√ßar ‚Äúno chute‚Äù, foram criadas formas melhores de escolher pesos iniciais.  \n\t  Resultado: Evita que a rede fique ‚Äúpresa‚Äù logo no in√≠cio.\n    "},
		{"id":"198300ff2982e365","x":320,"y":2223,"width":628,"height":160,"type":"text","text":"\n4. **Regulariza√ß√£o**\n\t- Redes profundas t√™m muita capacidade ‚Üí risco de **decorar o treino (overfitting)**.\n\t- T√©cnicas como **Dropout** (desliga neur√¥nios aleat√≥rios durante treino) e **BatchNorm** (normaliza ativa√ß√µes) ajudam a generalizar melhor."},
		{"id":"3286f56b81d54bcd","x":320,"y":2423,"width":628,"height":120,"type":"text","text":"\n5. **Infraestrutura Computacional**\n\t- GPUs e TPUs entraram em cena ‚Üí agora era poss√≠vel treinar **redes gigantes**.  \n    Resultado: Isso abriu espa√ßo para o **boom do Deep Learning**."},
		{"id":"2896c83453c438f5","x":-40,"y":2840,"width":300,"height":60,"type":"text","text":"### Arquiteturas alternativas"},
		{"id":"b9d6aea5b7f26f45","x":-301,"y":1818,"width":453,"height":65,"type":"text","text":"surgiu como evolu√ß√£o do MLP, resolvendo o problema do gradiente e adicionando novas t√©cnicas"},
		{"id":"1ba17e2d666461c1","x":460,"y":2700,"width":265,"height":75,"type":"text","text":"#### CNNs: Redes Neurais Convolucionais"},
		{"id":"8a97647d5257c058","x":840,"y":2552,"width":866,"height":148,"type":"text","text":"**Por que surgiram?**\n- O **MLP** n√£o lida bem com imagens: cada pixel vira uma entrada, o que implica em: imagens grandes = milhares de vari√°veis!\n- Al√©m disso, o MLP **n√£o entende que pixels vizinhos t√™m rela√ß√£o** (um olho ao lado do outro, por exemplo)."},
		{"id":"de2a175a4e71e240","x":840,"y":2734,"width":866,"height":106,"type":"text","text":" **Inspira√ß√£o biol√≥gica**\n- Estudos de vis√£o mostraram que nossos olhos enviam sinais processados em v√°rias camadas no c√©rebro.\n- As CNNs imitam isso: **convolu√ß√µes ‚Üí abstra√ß√µes ‚Üí decis√£o final**."},
		{"id":"7a9521a26198cff0","x":840,"y":2880,"width":866,"height":202,"type":"text","text":" **Exemplos de uso**\n\n- **Vis√£o computacional**: reconhecimento facial, classifica√ß√£o de imagens, detec√ß√£o de objetos.\n    \n- **Sa√∫de**: an√°lise de exames m√©dicos (raios-X, resson√¢ncia magn√©tica).\n    \n- **Processamento de v√≠deo**: vigil√¢ncia, carros aut√¥nomos.\n    \n- **√Åudio e texto**: apesar de serem mais usadas em imagens, CNNs tamb√©m podem ser aplicadas em sinais de √°udio ou at√© em NLP (para detectar padr√µes em sequ√™ncias de palavras)."},
		{"id":"23fddb2aa0c2700c","x":1800,"y":2460,"width":535,"height":140,"type":"text","text":"a CNN consegue **enxergar padr√µes em diferentes n√≠veis** e funciona como um **detector de padr√µes locais** com filtros reutiliz√°veis:\n\n- Primeiras camadas ‚Üí detectam linhas e bordas.\n    \n- Camadas mais profundas ‚Üí detectam rostos, objetos, contextos."},
		{"id":"8236415da3611906","x":1800,"y":2620,"width":535,"height":213,"type":"text","text":"**Transfer Learning** (transfer√™ncia de aprendizado)\n\n- CNNs grandes podem ser **pr√©-treinadas em bases enormes** (ex.: ImageNet). Treinamento 1.\n- Depois, esse conhecimento √© **ajustado (fine-tuning)** em bases menores.  Treinamento 2 usa o Treinamento 1.\nIsso permitiu aplicar CNNs em muitos problemas mesmo sem tantos dados."},
		{"id":"d5318bfd9425d5b2","x":2420,"y":2679,"width":388,"height":95,"type":"text","text":"Ao retreinar, a rede aproveita o conhecimento adquirido no treino inicial sobre os objetos e o adapta para a nova tarefa."},
		{"id":"f5c9e2d77c427241","x":460,"y":3420,"width":165,"height":50,"type":"text","text":"#### _Transformer_"},
		{"id":"47d92226d491edf4","x":840,"y":3140,"width":937,"height":149,"type":"text","text":"**O que s√£o?**\n- Uma arquitetura criada para **tradu√ß√£o de textos**, mas que acabou revolucionando **linguagem, √°udio e at√© vis√£o**.\n- O segredo est√° no **mecanismo de aten√ß√£o** ‚Üí o modelo n√£o l√™ tudo igual, ele **foca no que √© mais importante** em cada parte do texto ou dado."},
		{"id":"49750ee651f1eb68","x":1940,"y":3140,"width":597,"height":149,"type":"text","text":"Exemplo simples:  \n\tNa frase _‚ÄúO gato subiu no telhado porque ele estava assustado‚Äù_,\n- O ‚Äúele‚Äù se refere ao **gato**.\n- O Transformer consegue dar mais ‚Äúpeso‚Äù ao **gato** quando interpreta ‚Äúele‚Äù."},
		{"id":"6d84f32ab4f853fd","x":841,"y":3316,"width":936,"height":154,"type":"text","text":"**Como funciona a Aten√ß√£o**\n\n- O modelo **atribui pesos diferentes** √†s palavras (ou partes do dado).\n    \n- Isso permite **entender contexto** de forma muito melhor que os modelos antigos (RNNs e LSTMs).\n    \n- Resultado ‚Üí redes mais r√°pidas, paraleliz√°veis e eficientes."},
		{"id":"1c2dd7ea6f0b2de7","x":1940,"y":3316,"width":593,"height":154,"type":"text","text":"**Impacto**\n- Foi como a **AlexNet em 2012 para imagens** ‚Üí os Transformers fizeram o mesmo para **linguagem natural**.\n- Permitiram o surgimento de **pr√©-treino em larga escala** ‚Üí treina em bilh√µes de palavras e depois adapta (fine-tuning) para tarefas espec√≠ficas."},
		{"id":"e7fbc3d5a18b615a","x":2642,"y":3194,"width":738,"height":226,"type":"text","text":"**Exemplos famosos de modelos baseados em Transformers**\n\n- **BERT** (Google, 2018) ‚Üí entende contexto de frases (usado em pesquisa Google).\n    \n- **GPT** (OpenAI, 2018+) ‚Üí gera textos (base dos ChatGPT).\n    \n- **LLaMA** (Meta, 2023) ‚Üí modelo aberto usado em pesquisa.\n    \n- **Whisper** (OpenAI) ‚Üí transcri√ß√£o e tradu√ß√£o de fala.\n    \n- **Wav2Vec, HuBERT, Tacotron** ‚Üí reconhecimento e s√≠ntese de voz.\n    \n- **Vision Transformers (ViT)** ‚Üí adapta√ß√£o para imagens (classifica√ß√£o, detec√ß√£o, segmenta√ß√£o)."},
		{"id":"07d10a4d983cd750","x":840,"y":3660,"width":498,"height":166,"type":"text","text":"**Exemplos do que conseguem gerar:**\n\n- üñºÔ∏è Imagens hiper-realistas (ex.: DALL¬∑E, Stable Diffusion)\n    \n- üéµ M√∫sicas e vozes sint√©ticas\n    \n- üé¨ V√≠deos artificiais\n    \n- üñäÔ∏è Textos e hist√≥rias"},
		{"id":"7378b356f18c07d3","x":840,"y":3520,"width":698,"height":100,"type":"text","text":" **O que s√£o?**\n- Redes que **n√£o s√≥ entendem dados, mas tamb√©m criam coisas novas**.\n- Usam os grandes conjuntos de dados da internet como combust√≠vel.\n"},
		{"id":"2ff16b46d7a32c2d","x":416,"y":3660,"width":306,"height":54,"type":"text","text":"#### Rede Neurais Generativas"},
		{"id":"2955a9e047c71ed1","x":416,"y":3960,"width":250,"height":60,"type":"text","text":"#### _Frameworks_¬†para DL"},
		{"id":"a3be7f7ee51643e2","x":840,"y":3883,"width":698,"height":137,"type":"text","text":"**Antes dos frameworks**\n- Programar redes direto em **CUDA (linguagem da Nvidia para GPUs)** era **dif√≠cil e trabalhoso**.\n- Isso limitava pesquisadores e empresas."},
		{"id":"76c888867243da20","x":840,"y":4060,"width":698,"height":120,"type":"text","text":"**A revolu√ß√£o**\n\nPara simplificar, surgiram frameworks que **escondem a complexidade do CUDA** e d√£o uma interface mais amig√°vel.  \n\n"},
		{"id":"b26cf4b434779464","x":840,"y":4240,"width":698,"height":140,"type":"text","text":" **Por que s√£o importantes?**\n- Tornaram o **treinamento de RNAs acess√≠vel** a qualquer pessoa com Python.\n- Aceleraram a cria√ß√£o de novas arquiteturas e experimentos.\n- Foram fundamentais para a explos√£o do **Deep Learning** nos √∫ltimos anos."},
		{"id":"b7dad5f551617be9","x":1706,"y":4040,"width":570,"height":160,"type":"text","text":"Principais:\n\n- **TensorFlow (Google, 2015)** ‚Üí open source, muito usado em produ√ß√£o.\n    \n- **PyTorch (Meta/Facebook, 2016)** ‚Üí simples, flex√≠vel, favorito em pesquisa."}
	],
	"edges":[
		{"id":"3f9d4b16bf916dd8","fromNode":"0f1c06ed1aa9df24","fromSide":"right","toNode":"12d3c74b249c8236","toSide":"left"},
		{"id":"be7e4c396bde8ae9","fromNode":"0f1c06ed1aa9df24","fromSide":"top","toNode":"0508fc7b9734a8e2","toSide":"left"},
		{"id":"7078344b5ef7a894","fromNode":"12d3c74b249c8236","fromSide":"right","toNode":"cd8c4fc8b24ca725","toSide":"left"},
		{"id":"4f879c21e9899f27","fromNode":"cd8c4fc8b24ca725","fromSide":"right","toNode":"3b56db8d58325d5e","toSide":"left"},
		{"id":"5d527c36fe510527","fromNode":"12d3c74b249c8236","fromSide":"right","toNode":"99cd4043facd89ba","toSide":"left"},
		{"id":"b86dcd6cf96fef15","fromNode":"3b56db8d58325d5e","fromSide":"bottom","toNode":"85969565cd5a2914","toSide":"top"},
		{"id":"478cc0aec808a330","fromNode":"3b56db8d58325d5e","fromSide":"right","toNode":"f26411fdc298c78f","toSide":"left"},
		{"id":"28c2a86f2ab03936","fromNode":"0f1c06ed1aa9df24","fromSide":"right","toNode":"b0f49c4cff9aee22","toSide":"left"},
		{"id":"69e9c0382da47575","fromNode":"b0f49c4cff9aee22","fromSide":"right","toNode":"6345ac466a23dda8","toSide":"left"},
		{"id":"8d6b2a3957c57cd7","fromNode":"6345ac466a23dda8","fromSide":"bottom","toNode":"3fb03f4067ee081f","toSide":"top"},
		{"id":"ad5e978ba94cfe8d","fromNode":"3fb03f4067ee081f","fromSide":"right","toNode":"47a227896098ccfd","toSide":"left"},
		{"id":"f0275d097b95018b","fromNode":"50efc7e79c51ccdf","fromSide":"right","toNode":"d15127852aafe292","toSide":"left"},
		{"id":"a3821f13979b43cd","fromNode":"50efc7e79c51ccdf","fromSide":"right","toNode":"4bf298160d55b783","toSide":"left"},
		{"id":"fece5165cd5ceadf","fromNode":"3fb03f4067ee081f","fromSide":"bottom","toNode":"50efc7e79c51ccdf","toSide":"top"},
		{"id":"5bd7b25e9b80a4c5","fromNode":"4bf298160d55b783","fromSide":"bottom","toNode":"026680ebf14a7a64","toSide":"left"},
		{"id":"3018c1d9516f94d6","fromNode":"0f1c06ed1aa9df24","fromSide":"bottom","toNode":"8e56c2650c5876ab","toSide":"left"},
		{"id":"b2c3495d1e01fc77","fromNode":"026680ebf14a7a64","fromSide":"top","toNode":"b56f100048e0b276","toSide":"left"},
		{"id":"3b19261afcf1a2d8","fromNode":"8e56c2650c5876ab","fromSide":"right","toNode":"f656313c32173be0","toSide":"left"},
		{"id":"d3156e6d0ddd232a","fromNode":"f656313c32173be0","fromSide":"right","toNode":"d08a1039429fd729","toSide":"left"},
		{"id":"269410b1c59ece21","fromNode":"f656313c32173be0","fromSide":"right","toNode":"a859daefde709b23","toSide":"left"},
		{"id":"c2657ba3b0e2b0bc","fromNode":"f656313c32173be0","fromSide":"right","toNode":"8f6b6c923b423858","toSide":"left"},
		{"id":"463fbde9f8c1bf90","fromNode":"f656313c32173be0","fromSide":"right","toNode":"198300ff2982e365","toSide":"left"},
		{"id":"a99d7a2a395703ab","fromNode":"f656313c32173be0","fromSide":"right","toNode":"3286f56b81d54bcd","toSide":"left"},
		{"id":"758fd70009149da3","fromNode":"f656313c32173be0","fromSide":"bottom","toNode":"2896c83453c438f5","toSide":"left"},
		{"id":"bdd8df6453050b6a","fromNode":"2896c83453c438f5","fromSide":"right","toNode":"1ba17e2d666461c1","toSide":"left"},
		{"id":"deca42f6ec6c8e2d","fromNode":"2896c83453c438f5","fromSide":"right","toNode":"f5c9e2d77c427241","toSide":"left"},
		{"id":"e3aa82e38cb11941","fromNode":"2896c83453c438f5","fromSide":"right","toNode":"2ff16b46d7a32c2d","toSide":"left"},
		{"id":"e38a6eac6fa48eac","fromNode":"2896c83453c438f5","fromSide":"right","toNode":"2955a9e047c71ed1","toSide":"left"},
		{"id":"4445f0b8db6f45f0","fromNode":"8e56c2650c5876ab","fromSide":"top","toNode":"b9d6aea5b7f26f45","toSide":"left"},
		{"id":"a05bd4272a48c09e","fromNode":"1ba17e2d666461c1","fromSide":"right","toNode":"8a97647d5257c058","toSide":"left"},
		{"id":"4dc6c4572fbd3f3b","fromNode":"1ba17e2d666461c1","fromSide":"right","toNode":"de2a175a4e71e240","toSide":"left"},
		{"id":"562b37dd5bb3abe0","fromNode":"1ba17e2d666461c1","fromSide":"right","toNode":"7a9521a26198cff0","toSide":"left"},
		{"id":"eaf68cc9926219e1","fromNode":"8a97647d5257c058","fromSide":"right","toNode":"23fddb2aa0c2700c","toSide":"left"},
		{"id":"ab2a2f10a832bff3","fromNode":"8a97647d5257c058","fromSide":"right","toNode":"8236415da3611906","toSide":"left"},
		{"id":"e4a862edbd238684","fromNode":"8236415da3611906","fromSide":"right","toNode":"d5318bfd9425d5b2","toSide":"left"},
		{"id":"beca79ae309853a1","fromNode":"f5c9e2d77c427241","fromSide":"right","toNode":"47d92226d491edf4","toSide":"left"},
		{"id":"6fc3a7a4bc687ad2","fromNode":"47d92226d491edf4","fromSide":"right","toNode":"49750ee651f1eb68","toSide":"left"},
		{"id":"9d525fc272631aa6","fromNode":"f5c9e2d77c427241","fromSide":"right","toNode":"6d84f32ab4f853fd","toSide":"left"},
		{"id":"ecad0fb3e4536418","fromNode":"6d84f32ab4f853fd","fromSide":"right","toNode":"1c2dd7ea6f0b2de7","toSide":"left"},
		{"id":"41ebdbaac5451d5f","fromNode":"1c2dd7ea6f0b2de7","fromSide":"right","toNode":"e7fbc3d5a18b615a","toSide":"left"},
		{"id":"6d423ff1b1ce4155","fromNode":"2ff16b46d7a32c2d","fromSide":"right","toNode":"7378b356f18c07d3","toSide":"left"},
		{"id":"5fbb7432d578077b","fromNode":"2ff16b46d7a32c2d","fromSide":"right","toNode":"07d10a4d983cd750","toSide":"left"},
		{"id":"7f11a1af6db2ec32","fromNode":"2955a9e047c71ed1","fromSide":"right","toNode":"a3be7f7ee51643e2","toSide":"left"},
		{"id":"d4588f48d8d6267b","fromNode":"2955a9e047c71ed1","fromSide":"right","toNode":"76c888867243da20","toSide":"left"},
		{"id":"b8e41a7c03eefab6","fromNode":"76c888867243da20","fromSide":"right","toNode":"b7dad5f551617be9","toSide":"left"},
		{"id":"0ab066d24ff77fea","fromNode":"2955a9e047c71ed1","fromSide":"right","toNode":"b26cf4b434779464","toSide":"left"}
	]
}